{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql.types import StructType, StructField, StringType, ArrayType, IntegerType, DoubleType, DateType\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.ml.feature import SQLTransformer\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "sc = SparkContext(master='local', appName='ETL_Job')\n",
    "spark = SparkSession(sparkContext=sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_id: struct<$oid:string>, title: string, genres: array<string>, plot: string, cast: array<string>, directors: array<string>]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.read.format('json').option('inferSchema', 'true').load(r'source_files/movies.json')\n",
    "\n",
    "selected_columns = ['_id', 'title', 'genres', 'plot', 'cast', 'directors']\n",
    "\n",
    "df = df.select(selected_columns)\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"_id\", StructType([StructField(\"$oid\", StringType())]), True),\n",
    "    StructField(\"title\", StringType(), True),\n",
    "    StructField(\"genres\", ArrayType(StringType()), True),\n",
    "    StructField(\"plot\", StringType(), True),\n",
    "    StructField(\"cast\", ArrayType(StringType()), True),\n",
    "    StructField(\"directors\", ArrayType(StringType()), True)])\n",
    "df.to(schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@udf(ArrayType(StringType()))\n",
    "def get_list(x):\n",
    "    if isinstance(x, list):\n",
    "        names = [name for name in x if name]  # Remove None values\n",
    "        if len(names) > 5:\n",
    "            names = names[:5]\n",
    "        return names\n",
    "    return []\n",
    "\n",
    "featured_columns = ['genres', 'cast', 'directors']\n",
    "\n",
    "for column in featured_columns:\n",
    "    df = df.withColumn(column, get_list(col(column)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@udf(ArrayType(StringType()))\n",
    "def clean_data(row):\n",
    "    if isinstance(row, list):\n",
    "        return [re.sub(r'[^a-zA-Z0-9]', '', i).lower() for i in row]\n",
    "    elif isinstance(row, str):\n",
    "        return [re.sub(r'[^a-zA-Z0-9]', '', row).lower()]\n",
    "    return []\n",
    "\n",
    "for column in featured_columns:\n",
    "    df = df.withColumn(column, clean_data(col(column)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@udf(ArrayType(StringType()))\n",
    "def merge_cols(genres, cast, directors):\n",
    "    return list(genres + cast + directors)\n",
    "\n",
    "df = df.withColumn('tokens', merge_cols('genres', 'cast', 'directors'))\n",
    "\n",
    "df_2 = df.select('title', 'tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "277028195\n",
      "19.88704562187195\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "# Use CountVectorizer to convert text data to a feature vector\n",
    "cv = CountVectorizer(inputCol=\"tokens\", outputCol=\"features\")\n",
    "cv_model = cv.fit(df_2)\n",
    "count_matrix = cv_model.transform(df_2)\n",
    "\n",
    "# Calculate cosine similarity\n",
    "dot_udf = F.udf(lambda x, y: float(x.dot(y)), 'double')\n",
    "cosine_sim = count_matrix.alias(\"i\").join(count_matrix.alias(\"j\"), F.col(\"i.title\") < F.col(\"j.title\")) \\\n",
    "    .select(\n",
    "        F.col(\"i.title\").alias(\"title_i\"),\n",
    "        F.col(\"j.title\").alias(\"title_j\"),\n",
    "        dot_udf(\"i.features\", \"j.features\").alias(\"cosine_similarity\")\n",
    "    )\n",
    "print(cosine_sim.count())\n",
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "277028195"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_sim.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "\n",
    "sc = SparkContext(master='local', appName='test')\n",
    "spark = SparkSession(sparkContext=sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = spark.read.format('json').option('inferSchema', 'true').load(r'source_files/movies(mongodb).json')\n",
    "# df2 = spark.read.format('csv').option('inferSchema', 'true').load(r'C:/Users/mohammbaig/Documents/My files/Python/Mini_projects/Movie_recommender/tmdb_5000_movies.csv')\n",
    "df2 = spark.read.csv(r\"C:/Users/mohammbaig/Documents/My files/Python/Mini_projects/Movie_recommender/tmdb_5000_movies.csv\", header=True, multiLine=True, escape='\"', inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- title: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.select('title').printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- title: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.select('title').printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[budget: int, genres: string, homepage: string, id: int, keywords: string, original_language: string, original_title: string, overview: string, popularity: double, production_companies: string, production_countries: string, release_date: date, revenue: bigint, runtime: double, spoken_languages: string, status: string, tagline: string, title: string, vote_average: double, vote_count: int]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.alias(\"df1\")\n",
    "df2.alias(\"df2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "join=df1.join(df2, on=(df1['title'] == df2['title']), how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21349 21349 21349 19744\n",
      "19744 19744 19744 19744\n"
     ]
    }
   ],
   "source": [
    "print(df1.count(),\n",
    "      df1.distinct().count(),\n",
    "      df1.select('title').count(),\n",
    "      df1.select('title').distinct().count())\n",
    "df1 = df1.dropDuplicates(['title'])\n",
    "print(df1.count(),\n",
    "      df1.distinct().count(),\n",
    "      df1.select('title').count(),\n",
    "      df1.select('title').distinct().count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4803 4803 4803 4800\n",
      "4800 4800 4800 4800\n"
     ]
    }
   ],
   "source": [
    "print(df2.count(),\n",
    "      df2.distinct().count(),\n",
    "      df2.select('title').count(),\n",
    "      df2.select('title').distinct().count())\n",
    "df2 = df2.dropDuplicates(['title'])\n",
    "print(df2.count(),\n",
    "      df2.distinct().count(),\n",
    "      df2.select('title').count(),\n",
    "      df2.select('title').distinct().count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3610\n"
     ]
    }
   ],
   "source": [
    "df1.createOrReplaceTempView('df1')\n",
    "df2.createOrReplaceTempView('df2')\n",
    "join2 = spark.sql(\n",
    "    '''\n",
    "    select df2.*, df1.poster from df1 inner join df2 on df1.title = df2.title;\n",
    "    '''\n",
    ")\n",
    "print(join2.count())\n",
    "\n",
    "# pdf = join2.toPandas()\n",
    "# pdf.to_json('movies.json', orient='records')\n",
    "\n",
    "\n",
    "pdf = join2.toPandas()\n",
    "pdf['title'].to_csv('titles.txt', index=False, header=False, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "\n",
    "sc = SparkContext(master='local', appName='test')\n",
    "spark = SparkSession(sc)\n",
    "\n",
    "# rdd = sc.parallelize([1,2,3])\n",
    "# rdd.collect()\n",
    "\n",
    "df = spark.createDataFrame([{\"name\": \"John\", \"age\": 30}])\n",
    "df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.csv(\"newfolder\", header=True, mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "import os\n",
    "import re\n",
    "\n",
    "connection = MongoClient(os.getenv(\"MONGO_URI\"))\n",
    "db = connection[\"Recommendations_project\"]\n",
    "collection = db.get_collection(\"source_movies\")\n",
    "\n",
    "regex_pattern = re.compile(\"the\", re.IGNORECASE)\n",
    "query = {\n",
    "            \"$or\": [\n",
    "                {\"title\": {\"$regex\": regex_pattern}}\n",
    "                # {\"cast\": {\"$regex\": regex_pattern}},\n",
    "                # {\"genres\": {\"$regex\": regex_pattern}},\n",
    "                # {\"plot\": {\"$regex\": regex_pattern}},\n",
    "                # {\"directors\": {\"$regex\": regex_pattern}},\n",
    "            ]\n",
    "        }\n",
    "# offset = page * self.page_size\n",
    "\n",
    "# logging.info(\"searching movies for input %s\", query_str)\n",
    "cursor = collection.find(query).limit(10)\n",
    "list(cursor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
